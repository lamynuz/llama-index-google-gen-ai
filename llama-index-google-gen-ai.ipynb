{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf5a754",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index\n",
    "%pip install llama-index-llms-palm\n",
    "%pip install pypdf\n",
    "%pip install docx2txt\n",
    "%pip install google-generativeai\n",
    "%pip install transformers\n",
    "\n",
    "# Additional to use Google GenAI Gemini\n",
    "%pip install llama-index-llms-google-genai\n",
    "%pip install google-genai\n",
    "%pip install llama-index-embeddings-google-genai\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76535ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "# Deprecated\n",
    "#from llama_index.llms.palm import PaLM\n",
    "from llama_index.llms.google_genai import GoogleGenAI\n",
    "from llama_index.core import ServiceContext\n",
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "os.environ['GOOGLE_API_KEY'] = GOOGLE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c750d3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"data\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "63a6bc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 22:18:31,080 - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from llama_index.embeddings.google_genai import GoogleGenAIEmbedding\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "Settings.llm = GoogleGenAI(model=\"gemini-2.0-flash\")\n",
    "Settings.embed_model = GoogleGenAIEmbedding(model_name=\"gemini-embedding-001\")\n",
    "Settings.node_parser = SentenceSplitter(chunk_size=512, chunk_overlap=20)\n",
    "Settings.num_output = 512\n",
    "Settings.context_window = 3900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "10d93c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 22:01:32,371 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-001:batchEmbedContents \"HTTP/1.1 200 OK\"\n",
      "2025-09-29 22:01:32,765 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-001:batchEmbedContents \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c97922",
   "metadata": {},
   "source": [
    "# Store and load the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b26ccaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save, it will store in a directory called storage\n",
    "index.storage_context.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422ed6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "#storage_context = StorageContext.from_defaults(persist_dir='./storage')\n",
    "#index = load_index_from_storage(storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7125af97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 22:23:09,730 - INFO - AFC is enabled with max remote calls: 10.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.async_utils import asyncio_run\n",
    "\n",
    "query_engine = index.as_query_engine()\n",
    "# Python forbids creating one loop when another loop is already running\n",
    "async def run():\n",
    "    return await query_engine.aquery(\"What they eay?\") \n",
    "response = await run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0fcaceb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Some dinosaurs consumed plants, others consumed meat, and some even consumed other dinosaurs.\n",
       "</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "28-LlamaIndex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
